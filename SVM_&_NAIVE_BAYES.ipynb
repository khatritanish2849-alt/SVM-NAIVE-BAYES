{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM & NAIVE BAYES :**"
      ],
      "metadata": {
        "id": "vNesIhYZ5nW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRACTICAL QUESTIONS :**"
      ],
      "metadata": {
        "id": "r17etOQw5vK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 21 :Write a Python program to train an SVM Classifier on the Iris dataset and evaluate accuracy.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "SVM Classifier on Iris Dataset\n",
        "\n",
        "    from sklearn.datasets import load_iris\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.svm import SVC\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    X, y = load_iris(return_X_y=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = SVC()\n",
        "    model.fit(X_train, y_train)\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "hEk_3V3s50-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 22 : Write a Python program to train two SVM classifiers with Linear and RBF kernels on the Wine dataset, then compare their accuracies.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Linear vs RBF Kernel – Wine Dataset\n",
        "\n",
        "    from sklearn.datasets import load_wine\n",
        "    from sklearn.svm import SVC\n",
        "\n",
        "    X, y = load_wine(return_X_y=True)\n",
        "\n",
        "    for kernel in ['linear', 'rbf']:\n",
        "    model = SVC(kernel=kernel)\n",
        "    model.fit(X, y)\n",
        "    print(kernel, \"Accuracy:\", model.score(X, y))\n"
      ],
      "metadata": {
        "id": "Kfi-PWab65_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 23 : Write a Python program to train an SVM Regressor (SVR) on a housing dataset and evaluate it using Mean\n",
        "Squared Error (MSE).**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "SVR on Housing Dataset (MSE)\n",
        "\n",
        "    from sklearn.datasets import fetch_california_housing\n",
        "    from sklearn.svm import SVR\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "\n",
        "    X, y = fetch_california_housing(return_X_y=True)\n",
        "\n",
        "    model = SVR()\n",
        "    model.fit(X, y)\n",
        "    print(\"MSE:\", mean_squared_error(y, model.predict(X)))\n",
        "\n"
      ],
      "metadata": {
        "id": "Q31Ee2pS7LW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 24 : Write a Python program to train an SVM Classifier with a Polynomial Kernel and visualize the decision boundary.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.datasets import make_classification\n",
        "    from sklearn.svm import SVC\n",
        "\n",
        "# Generate a 2D synthetic dataset\n",
        "\n",
        "    X, y = make_classification(\n",
        "    \n",
        "    n_samples=200,\n",
        "    n_features=2,\n",
        "    n_redundant=0,\n",
        "    n_clusters_per_class=1,\n",
        "    random_state=42\n",
        "    )\n",
        "\n",
        "# Train SVM with Polynomial Kernel\n",
        "\n",
        "    model = SVC(kernel='poly', degree=3, C=1)\n",
        "    model.fit(X, y)\n",
        "\n",
        "# Create mesh grid for visualization\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(\n",
        "    np.linspace(x_min, x_max, 300),\n",
        "    np.linspace(y_min, y_max, 300)\n",
        "    )\n",
        "\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot decision boundary\n",
        "    plt.contourf(xx, yy, Z, alpha=0.3)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k')\n",
        "    plt.title(\"SVM with Polynomial Kernel (Decision Boundary)\")\n",
        "    plt.xlabel(\"Feature 1\")\n",
        "    plt.ylabel(\"Feature 2\")\n",
        "    plt.show()\n",
        "\n",
        "#Explanation:\n",
        "\n",
        "A synthetic 2-D dataset is created to allow visualization.\n",
        "\n",
        "An SVM classifier is trained using a Polynomial kernel of degree 3.\n",
        "\n",
        "A mesh grid is generated to predict class labels over the feature space.\n",
        "\n",
        "The decision boundary is visualized using a contour plot.\n",
        "\n",
        "#CONCLUSION:\n",
        "\n",
        "The Polynomial Kernel allows SVM to model non-linear decision boundaries, making it effective for datasets where classes are not linearly separable."
      ],
      "metadata": {
        "id": "xJFzrAn97mIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 25 : Write a Python program to train a Gaussian Naive Bayes classifier on the Breast Cancer dataset and evaluate accuracy.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Gaussian NB – Breast Cancer Dataset\n",
        "\n",
        "    from sklearn.datasets import load_breast_cancer\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "    X, y = load_breast_cancer(return_X_y=True)\n",
        "    model = GaussianNB()\n",
        "    model.fit(X, y)\n",
        "    print(\"Accuracy:\", model.score(X, y))\n"
      ],
      "metadata": {
        "id": "Yfe75qG-83Aw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 26 : Write a Python program to train a Multinomial Naïve Bayes classifier for text classification using the 20\n",
        "Newsgroups dataset.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Multinomial NB – 20 Newsgroups\n",
        "\n",
        "    from sklearn.datasets import fetch_20newsgroups\n",
        "    from sklearn.feature_extraction.text import CountVectorizer\n",
        "    from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "    data = fetch_20newsgroups()\n",
        "    X = CountVectorizer().fit_transform(data.data)\n",
        "    y = data.target\n",
        "\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X, y)\n",
        "    print(\"Accuracy:\", model.score(X, y))\n"
      ],
      "metadata": {
        "id": "V7CjsVVteB1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 27 : Write a Python program to train an SVM Classifier with different C values and compare the decision boundaries visually.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "SVM with Different C Values\n",
        "\n",
        "    from sklearn.svm import SVC\n",
        "\n",
        "    for C in [0.1, 1, 10]:\n",
        "    model = SVC(C=C)\n",
        "    model.fit(X, y)\n",
        "    print(\"C =\", C, \"Accuracy:\", model.score(X, y))\n"
      ],
      "metadata": {
        "id": "kC6V-Jv2egLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 28 : Write a Python program to train a Bernoulli Naïve Bayes classifier for binary classification on a dataset with binary features.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Bernoulli NB (Binary Data)\n",
        "\n",
        "    from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "    X_bin = (X > 0).astype(int)\n",
        "    model = BernoulliNB()\n",
        "    model.fit(X_bin, y)\n",
        "    print(\"Accuracy:\", model.score(X_bin, y))\n"
      ],
      "metadata": {
        "id": "EE4xa5yJevO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 29 : Write a Python program to apply feature scaling before training an SVM model and compare results with unscaled data.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Feature Scaling before SVM\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    print(\"Without Scaling:\", SVC().fit(X, y).score(X, y))\n",
        "    print(\"With Scaling:\", SVC().fit(X_scaled, y).score(X_scaled, y))\n"
      ],
      "metadata": {
        "id": "pVYpNzA8fIxK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 30 :Write a Python program to train a Gaussian Naïve Bayes model and compare the predictions before and after Laplace Smoothing.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Laplace Smoothing (Gaussian NB)\n",
        "\n",
        "    GaussianNB(var_smoothing=1e-9).fit(X, y)\n"
      ],
      "metadata": {
        "id": "mscpi1ayfkN7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 31 : Write a Python program to train an SVM Classifier and use GridSearchCV to tune the hyperparameters (C, gamma, kernel).**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "GridSearchCV for SVM\n",
        "\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "    params = {'C':[0.1,1,10],'kernel':['linear','rbf']}\n",
        "    grid = GridSearchCV(SVC(), params)\n",
        "    grid.fit(X, y)\n",
        "\n",
        "    print(\"Best Params:\", grid.best_params_)\n"
      ],
      "metadata": {
        "id": "KpP54CmOgbKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 32 : Write a Python program to train an SVM Classifier on an imbalanced dataset and apply class weighting and check it improve accuracy.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "SVM on Imbalanced Data\n",
        "\n",
        "    model = SVC(class_weight='balanced')\n",
        "    model.fit(X, y)\n",
        "    print(\"Accuracy:\", model.score(X, y))\n"
      ],
      "metadata": {
        "id": "sNv3r1EvgraH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 33 : Write a Python program to implement a Naive Bayes classifier for spam detection using email data.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Naive Bayes for Spam Detection\n",
        "\n",
        "    texts = [\"free money now\", \"hello friend\", \"win lottery\", \"meeting tomorrow\"]\n",
        "    labels = [1,0,1,0]\n",
        "\n",
        "    from sklearn.feature_extraction.text import CountVectorizer\n",
        "    from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "    X = CountVectorizer().fit_transform(texts)\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X, labels)\n"
      ],
      "metadata": {
        "id": "QH9Kw-2ng6WV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 34 : Write a Python program to train an SVM Classifier and a Naïve Bayes Classifier on the same dataset and compare their accuracy.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "SVM vs Naive Bayes\n",
        "\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "    print(\"SVM:\", SVC().fit(X, y).score(X, y))\n",
        "    print(\"NB:\", GaussianNB().fit(X, y).score(X, y))\n"
      ],
      "metadata": {
        "id": "NabV82jQhM4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 35 : Write a Python program to perform feature selection before training a Naïve Bayes classifier and compare results.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Feature Selection before NB\n",
        "\n",
        "    from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "    X_new = SelectKBest(chi2, k=10).fit_transform(abs(X), y)\n",
        "    GaussianNB().fit(X_new, y)\n"
      ],
      "metadata": {
        "id": "3LiqBgRDhbWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 36 : Write a Python program to train an SVM Classifier using One-vs-Rest (OVR) and One-vs-One (ovo)\n",
        "strategies on the Wine dataset and compare their accuracy.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "OvR vs OvO – Wine Dataset\n",
        "\n",
        "    SVC(decision_function_shape='ovr').fit(X, y)\n",
        "    SVC(decision_function_shape='ovo').fit(X, y)\n"
      ],
      "metadata": {
        "id": "pWmiRQL0hrAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 37 : Write a Python program to train an SVM Classifier using Linear, Polynomial, and RBF kernels on the Breast Cancer dataset and compare their accuracy.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Kernel Comparison – Breast Cancer\n",
        "\n",
        "    for k in ['linear','poly','rbf']:\n",
        "    print(k, SVC(kernel=k).fit(X, y).score(X, y))\n"
      ],
      "metadata": {
        "id": "bTaJMMLSh4W8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 38 : Write a Python program to train an SVM Classifier using Stratified K-Fold Cross-Validation and compute the average accuracy.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Stratified K-Fold CV\n",
        "\n",
        "    from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "    cv = StratifiedKFold(5)\n",
        "    print(cross_val_score(SVC(), X, y, cv=cv).mean())\n"
      ],
      "metadata": {
        "id": "D0QHpAq4iIrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 39 : Write a Python program to train a Naïve Bayes classifier using different prior probabilities and compare performance.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Different Priors – Naive Bayes\n",
        "\n",
        "    GaussianNB(priors=[0.7,0.3]).fit(X, y)\n"
      ],
      "metadata": {
        "id": "-m81M6S9jsyb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 40 : Write a Python program to perform Recursive Feature Elimination (RFE) before training an SVM Classifier and compare accuracy.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "RFE before SVM\n",
        "\n",
        "    from sklearn.feature_selection import RFE\n",
        "\n",
        "    selector = RFE(SVC(kernel='linear'), 10)\n",
        "    selector.fit(X, y)\n"
      ],
      "metadata": {
        "id": "17X8IVg9j5a_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 41 : Write a Python program to train an SVM Classifier and evaluate its performance using Precision, Recall, and Fl-Score instead of accuracy.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Precision, Recall, F1\n",
        "\n",
        "    from sklearn.metrics import classification_report\n",
        "\n",
        "    print(classification_report(y, SVC().fit(X,y).predict(X)))\n"
      ],
      "metadata": {
        "id": "N-gs_tKokX_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 42 : Write a Python program to train a Naive Bayes Classifier and evaluate its performance using Log Loss (Cross-Entropy Loss).**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Log Loss – Naive Bayes\n",
        "\n",
        "    from sklearn.metrics import log_loss\n",
        "\n",
        "    log_loss(y, GaussianNB().fit(X,y).predict_proba(X))\n"
      ],
      "metadata": {
        "id": "7jZUzX7Jkl5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 43 : Write a Python program to train an SVM Classifier and visualize the Confusion Matrix using seaborn.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Confusion Matrix\n",
        "\n",
        "    import seaborn as sns\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    sns.heatmap(confusion_matrix(y, SVC().fit(X,y).predict(X)), annot=True)\n"
      ],
      "metadata": {
        "id": "hAGMyctYkzcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 44 : Write a Python program to train an SVM Regressor (SVR) and evaluate its performance using Mean Absolute\n",
        "Error (MAE) instead of MSE.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "SVR with MAE\n",
        "\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "    mean_absolute_error(y, SVR().fit(X,y).predict(X))\n"
      ],
      "metadata": {
        "id": "bbT9AaBHlC1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 45 : Write a Python program to train a Naïve Bayes classifier and evaluate its performance using the ROC-AUC score.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "ROC-AUC – Naive Bayes\n",
        "\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "\n",
        "    roc_auc_score(y, GaussianNB().fit(X,y).predict_proba(X)[:,1])\n"
      ],
      "metadata": {
        "id": "Coxl4fe7lVrb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION 46 : Write a Python program to train an SVM Classifier and visualize the Precision-Recall Curve.**\n",
        "\n",
        "**ANSWER :**\n",
        "\n",
        "Precision–Recall Curve\n",
        "\n",
        "    from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "    precision, recall, _ = precision_recall_curve(\n",
        "    y, SVC(probability=True).fit(X,y).predict_proba(X)[:,1]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "ZDx0l-Q-ljWJ"
      }
    }
  ]
}